{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ee3e06-b5a9-472c-ba62-87f989fd9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SPSV Project - Phase 3: Feature Engineering & Dataset Integration\n",
    "\n",
    "\n",
    "# In step 1, I cleaned the five datasets.\n",
    "# In step 2, I performed EDA and found issues such as inconsistent categories (e.g., YES/NO vs Y/N).\n",
    "#\n",
    "# In stage 3, I am preparing the datasets for:\n",
    "# 1) Dashboard KPIs (counts, rates, trends by month/county/licence type)\n",
    "# 2) Machine learning (a single \"ML-ready\" table with engineered features)\n",
    "#\n",
    "# This stage focuses on:\n",
    "# - Creating meaningful features (binary flags, durations, rates, time buckets)\n",
    "# - Integrating datasets (linking complaints/inspections/enforcement back to licences)\n",
    "# - Producing summary tables for the dashboard and an ML dataset\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ede23f-fbab-45c6-a1ac-2a78f99e1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) LOAD CLEANED DATA\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# I load cleaned data to ensure I am building features on consistent categories and parsed dates.\n",
    "\n",
    "def load_csv(preferred_path: str, fallback_path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(preferred_path)\n",
    "    except FileNotFoundError:\n",
    "        return pd.read_csv(fallback_path)\n",
    "\n",
    "complaints = load_csv(\"spsv_complaints_clean.csv\", \"spsv_complaints.csv\")\n",
    "enforcement = load_csv(\"spsv_enforcement_clean.csv\", \"spsv_enforcement.csv\")\n",
    "inspections = load_csv(\"spsv_inspections_clean.csv\", \"spsv_inspections.csv\")\n",
    "licences = load_csv(\"spsv_licences_clean.csv\", \"spsv_licences.csv\")\n",
    "monthly_kpis = load_csv(\"spsv_monthly_kpis_clean.csv\", \"spsv_monthly_kpis.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) RE-CONFIRM DATETIME COLUMNS (required for time features)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Time-based features (monthly trends, rolling averages, expiry windows) require datetime columns.\n",
    "def to_datetime_safe(df: pd.DataFrame, col: str) -> None:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# These column names are based on what we used in Phase 2.\n",
    "# If your actual columns differ, the code will simply skip missing columns.\n",
    "to_datetime_safe(complaints, \"Date_Received\")\n",
    "to_datetime_safe(enforcement, \"Action_Date\")\n",
    "to_datetime_safe(inspections, \"Inspection_Date\")\n",
    "to_datetime_safe(licences, \"Issue_Date\")\n",
    "to_datetime_safe(licences, \"Expiry_Date\")\n",
    "to_datetime_safe(monthly_kpis, \"Month\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994cd748-9f28-45db-8c4b-8cfe50d5bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Column names (quick check) ---\n",
      "licences: ['Licence_ID', 'Licence_Type', 'Issue_Date', 'Expiry_Date', 'Status', 'County', 'Wheelchair_Accessible', 'Vehicle_Age', 'Vehicle_Plate_Year', 'Driver_Experience_Years', 'Fleet_Segment']\n",
      "complaints: ['Complaint_ID', 'Licence_ID', 'Complaint_Type', 'Date_Received', 'Resolved', 'Days_To_Resolution', 'Escalated']\n",
      "inspections: ['Inspection_ID', 'Licence_ID', 'Inspection_Date', 'Inspection_Type', 'Outcome', 'Breach_Category', 'Follow_Up_Required']\n",
      "enforcement: ['Enforcement_ID', 'Licence_ID', 'Action_Type', 'Action_Date', 'Outcome']\n",
      "monthly_kpis: ['Month', 'County', 'Inspections', 'Failures', 'Follow_Ups', 'Complaints', 'Escalations', 'Failure_Rate']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3) QUICK CHECK OF COLUMN NAMES\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n--- Column names (quick check) ---\")\n",
    "print(\"licences:\", list(licences.columns))\n",
    "print(\"complaints:\", list(complaints.columns))\n",
    "print(\"inspections:\", list(inspections.columns))\n",
    "print(\"enforcement:\", list(enforcement.columns))\n",
    "print(\"monthly_kpis:\", list(monthly_kpis.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a88ac44-abfd-4942-b8a3-bb8c24e8fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4) FIX A KNOWN DATA QUALITY ISSUE FOUND IN EDA (Wheelchair Accessible)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# EDA revealed inconsistent encoding in Wheelchair_Accessible (YES/NO vs Y/N).\n",
    "# I standardise it here because it directly affects accessibility KPIs and dashboard accuracy.\n",
    "if \"Wheelchair_Accessible\" in licences.columns:\n",
    "    licences[\"Wheelchair_Accessible\"] = (\n",
    "        licences[\"Wheelchair_Accessible\"]\n",
    "        .replace({\"Y\": \"YES\", \"N\": \"NO\"})\n",
    "        .astype(str)\n",
    "        .str.upper()\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) FEATURE ENGINEERING: LICENCES (licence-level features)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# The licences dataset is the \"anchor\" table because it contains geography (County),\n",
    "# licence type, and other stable attributes. Other datasets will be linked to it.\n",
    "lic = licences.copy()\n",
    "\n",
    "# 5.1 Binary accessibility flag\n",
    "if \"Wheelchair_Accessible\" in lic.columns:\n",
    "    lic[\"Is_Wheelchair_Accessible\"] = (lic[\"Wheelchair_Accessible\"] == \"YES\").astype(int)\n",
    "\n",
    "# 5.2 Vehicle age band (makes it more dashboard-friendly)\n",
    "if \"Vehicle_Age\" in lic.columns:\n",
    "    lic[\"Vehicle_Age_Band\"] = pd.cut(\n",
    "        lic[\"Vehicle_Age\"],\n",
    "        bins=[-np.inf, 2, 5, 10, np.inf],\n",
    "        labels=[\"0-2\", \"3-5\", \"6-10\", \"11+\"]\n",
    "    )\n",
    "\n",
    "# 5.3 Licence duration + expiring soon flag\n",
    "\n",
    "# Duration and expiry windows are useful for forecasting renewals and identifying future workload.\n",
    "if \"Issue_Date\" in lic.columns and \"Expiry_Date\" in lic.columns:\n",
    "    lic[\"Licence_Duration_Days\"] = (lic[\"Expiry_Date\"] - lic[\"Issue_Date\"]).dt.days\n",
    "\n",
    "    # \"Expiring soon\" is defined as expiring within the next 90 days from the latest date in the data.\n",
    "    reference_date = lic[\"Expiry_Date\"].max()\n",
    "    lic[\"Days_To_Expiry\"] = (lic[\"Expiry_Date\"] - reference_date).dt.days\n",
    "    lic[\"Is_Expiring_90_Days\"] = ((lic[\"Days_To_Expiry\"] <= 90) & (lic[\"Days_To_Expiry\"] >= 0)).astype(int)\n",
    "\n",
    "# 5.4 Standardise main categorical columns (small safety step)\n",
    "for col in [\"County\", \"Licence_Type\", \"Status\"]:\n",
    "    if col in lic.columns:\n",
    "        lic[col] = lic[col].astype(str).str.upper().str.strip()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) FEATURE ENGINEERING: COMPLAINTS (complaint-level features)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Complaints are a potential \"risk signal\". Here I create useful flags and time fields.\n",
    "comp = complaints.copy()\n",
    "\n",
    "# 6.1 Month field for grouping\n",
    "if \"Date_Received\" in comp.columns:\n",
    "    comp[\"Month\"] = comp[\"Date_Received\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# 6.2 Binary flags for escalated/resolved (works even if values are YES/NO, Y/N, True/False)\n",
    "def to_binary_yes_no(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.upper().str.strip()\n",
    "    return s.isin([\"YES\", \"Y\", \"TRUE\", \"1\"]).astype(int)\n",
    "\n",
    "if \"Escalated\" in comp.columns:\n",
    "    comp[\"Is_Escalated\"] = to_binary_yes_no(comp[\"Escalated\"])\n",
    "\n",
    "if \"Resolved\" in comp.columns:\n",
    "    comp[\"Is_Resolved\"] = to_binary_yes_no(comp[\"Resolved\"])\n",
    "\n",
    "# 6.3 Resolution speed band (dashboard-friendly)\n",
    "if \"Days_To_Resolution\" in comp.columns:\n",
    "    comp[\"Resolution_Speed_Band\"] = pd.cut(\n",
    "        comp[\"Days_To_Resolution\"],\n",
    "        bins=[-np.inf, 7, 14, 30, np.inf],\n",
    "        labels=[\"<=7 days\", \"8-14 days\", \"15-30 days\", \"31+ days\"]\n",
    "    )\n",
    "\n",
    "# 6.4 Standardise complaint type for grouping\n",
    "if \"Complaint_Type\" in comp.columns:\n",
    "    comp[\"Complaint_Type\"] = comp[\"Complaint_Type\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) FEATURE ENGINEERING: INSPECTIONS (inspection-level features)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Inspections are core compliance monitoring signals. I create a clear \"Is_Fail\" flag\n",
    "# to support county risk scoring and monthly failure rates.\n",
    "insp = inspections.copy()\n",
    "\n",
    "if \"Inspection_Date\" in insp.columns:\n",
    "    insp[\"Month\"] = insp[\"Inspection_Date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# \"Fail\" rules (simple and transparent)\n",
    "failure_labels = {\"FAIL\", \"FAILED\", \"NON-COMPLIANT\", \"NON COMPLIANT\"}\n",
    "if \"Outcome\" in insp.columns:\n",
    "    insp[\"Is_Fail\"] = insp[\"Outcome\"].astype(str).str.upper().isin(failure_labels).astype(int)\n",
    "\n",
    "# Follow-up required flag\n",
    "if \"Follow_Up_Required\" in insp.columns:\n",
    "    # handles YES/NO, Y/N, etc\n",
    "    insp[\"Is_Follow_Up_Required\"] = to_binary_yes_no(insp[\"Follow_Up_Required\"])\n",
    "\n",
    "# Breach category standardisation\n",
    "if \"Breach_Category\" in insp.columns:\n",
    "    insp[\"Breach_Category\"] = insp[\"Breach_Category\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) FEATURE ENGINEERING: ENFORCEMENT (action-level features)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Enforcement actions represent regulatory response. I create fields that help summarise severity and frequency.\n",
    "enf = enforcement.copy()\n",
    "\n",
    "if \"Action_Date\" in enf.columns:\n",
    "    enf[\"Month\"] = enf[\"Action_Date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "for col in [\"Action_Type\", \"Outcome\"]:\n",
    "    if col in enf.columns:\n",
    "        enf[col] = enf[col].astype(str).str.upper().str.strip()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) DATASET INTEGRATION (link everything back to licences)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# I join complaints/inspections/enforcement to licences using Licence_ID.\n",
    "# This enables analysis by County, Licence Type and Status.\n",
    "\n",
    "# Safety: only attempt merges if Licence_ID exists in both tables\n",
    "def safe_merge(left: pd.DataFrame, right: pd.DataFrame, on: str, how: str = \"left\") -> pd.DataFrame:\n",
    "    if on in left.columns and on in right.columns:\n",
    "        return left.merge(right, on=on, how=how)\n",
    "    else:\n",
    "        print(f\"WARNING: Could not merge because '{on}' not found in both tables.\")\n",
    "        return left.copy()\n",
    "\n",
    "# Licence columns to bring into operational tables\n",
    "lic_key_cols = [c for c in [\"Licence_ID\", \"County\", \"Licence_Type\", \"Status\", \"Is_Wheelchair_Accessible\", \"Vehicle_Age\", \"Vehicle_Age_Band\"] if c in lic.columns]\n",
    "\n",
    "comp_joined = safe_merge(comp, lic[lic_key_cols], on=\"Licence_ID\", how=\"left\")\n",
    "insp_joined = safe_merge(insp, lic[lic_key_cols], on=\"Licence_ID\", how=\"left\")\n",
    "enf_joined  = safe_merge(enf,  lic[lic_key_cols], on=\"Licence_ID\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10) DASHBOARD-READY SUMMARY TABLES\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Dashboards work best with aggregated tables (County/month summaries, KPI metrics).\n",
    "# I create two main summary outputs:\n",
    "# 1) county_monthly_summary: risk indicators by county and month\n",
    "# 2) licence_level_features: one row per licence with counts/flags (useful for ML)\n",
    "\n",
    "# 10.1 County-month summary from operational datasets\n",
    "# Complaints: counts + escalation rate\n",
    "if \"Month\" in comp_joined.columns and \"County\" in comp_joined.columns:\n",
    "    county_month_complaints = (\n",
    "        comp_joined\n",
    "        .groupby([\"County\", \"Month\"])\n",
    "        .agg(\n",
    "            Complaints=(\"Complaint_ID\", \"count\") if \"Complaint_ID\" in comp_joined.columns else (\"Licence_ID\", \"count\"),\n",
    "            Escalations=(\"Is_Escalated\", \"sum\") if \"Is_Escalated\" in comp_joined.columns else (\"Licence_ID\", \"count\")\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    if \"Escalations\" in county_month_complaints.columns and \"Complaints\" in county_month_complaints.columns:\n",
    "        county_month_complaints[\"Escalation_Rate\"] = county_month_complaints[\"Escalations\"] / county_month_complaints[\"Complaints\"]\n",
    "else:\n",
    "    county_month_complaints = pd.DataFrame()\n",
    "\n",
    "# Inspections: counts + failures + failure rate + follow-ups\n",
    "if \"Month\" in insp_joined.columns and \"County\" in insp_joined.columns:\n",
    "    county_month_inspections = (\n",
    "        insp_joined\n",
    "        .groupby([\"County\", \"Month\"])\n",
    "        .agg(\n",
    "            Inspections=(\"Inspection_ID\", \"count\") if \"Inspection_ID\" in insp_joined.columns else (\"Licence_ID\", \"count\"),\n",
    "            Failures=(\"Is_Fail\", \"sum\") if \"Is_Fail\" in insp_joined.columns else (\"Licence_ID\", \"count\"),\n",
    "            Follow_Ups=(\"Is_Follow_Up_Required\", \"sum\") if \"Is_Follow_Up_Required\" in insp_joined.columns else (\"Licence_ID\", \"count\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    county_month_inspections[\"Failure_Rate\"] = county_month_inspections[\"Failures\"] / county_month_inspections[\"Inspections\"]\n",
    "else:\n",
    "    county_month_inspections = pd.DataFrame()\n",
    "\n",
    "# Enforcement: counts by county-month\n",
    "if \"Month\" in enf_joined.columns and \"County\" in enf_joined.columns:\n",
    "    county_month_enforcement = (\n",
    "        enf_joined\n",
    "        .groupby([\"County\", \"Month\"])\n",
    "        .agg(\n",
    "            Enforcement_Actions=(\"Enforcement_ID\", \"count\") if \"Enforcement_ID\" in enf_joined.columns else (\"Licence_ID\", \"count\")\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "else:\n",
    "    county_month_enforcement = pd.DataFrame()\n",
    "\n",
    "# Combine county-month summaries into one table\n",
    "\n",
    "# I do an outer join to avoid losing county-month rows that exist in one dataset but not another.\n",
    "county_monthly_summary = None\n",
    "\n",
    "# Start with inspections (often the main compliance timeline)\n",
    "if not county_month_inspections.empty:\n",
    "    county_monthly_summary = county_month_inspections.copy()\n",
    "else:\n",
    "    # If inspections summary isn't available, start with complaints summary\n",
    "    county_monthly_summary = county_month_complaints.copy() if not county_month_complaints.empty else pd.DataFrame()\n",
    "\n",
    "if not county_month_complaints.empty:\n",
    "    county_monthly_summary = county_monthly_summary.merge(\n",
    "        county_month_complaints, on=[\"County\", \"Month\"], how=\"outer\"\n",
    "    )\n",
    "\n",
    "if not county_month_enforcement.empty:\n",
    "    county_monthly_summary = county_monthly_summary.merge(\n",
    "        county_month_enforcement, on=[\"County\", \"Month\"], how=\"outer\"\n",
    "    )\n",
    "\n",
    "# Fill remaining NaNs in numeric summary columns with 0 (because missing here often means \"no events that month\")\n",
    "num_cols = county_monthly_summary.select_dtypes(include=[np.number]).columns\n",
    "county_monthly_summary[num_cols] = county_monthly_summary[num_cols].fillna(0)\n",
    "\n",
    "# 10.2 Licence-level features (one row per licence)\n",
    "\n",
    "# This is useful for ML (e.g., predict high-risk licences) and also for dashboard drill-down.\n",
    "# I aggregate events per Licence_ID and attach them back to the licence table.\n",
    "\n",
    "# Complaints per licence\n",
    "if \"Licence_ID\" in comp.columns:\n",
    "    comp_per_lic = (\n",
    "        comp.groupby(\"Licence_ID\")\n",
    "            .agg(\n",
    "                Complaints=(\"Complaint_ID\", \"count\") if \"Complaint_ID\" in comp.columns else (\"Licence_ID\", \"count\"),\n",
    "                Escalations=(\"Is_Escalated\", \"sum\") if \"Is_Escalated\" in comp.columns else (\"Licence_ID\", \"count\"),\n",
    "                Avg_Days_To_Resolution=(\"Days_To_Resolution\", \"mean\") if \"Days_To_Resolution\" in comp.columns else (\"Licence_ID\", \"count\")\n",
    "            )\n",
    "            .reset_index()\n",
    "    )\n",
    "else:\n",
    "    comp_per_lic = pd.DataFrame()\n",
    "\n",
    "# Inspections per licence\n",
    "if \"Licence_ID\" in insp.columns:\n",
    "    insp_per_lic = (\n",
    "        insp.groupby(\"Licence_ID\")\n",
    "            .agg(\n",
    "                Inspections=(\"Inspection_ID\", \"count\") if \"Inspection_ID\" in insp.columns else (\"Licence_ID\", \"count\"),\n",
    "                Failures=(\"Is_Fail\", \"sum\") if \"Is_Fail\" in insp.columns else (\"Licence_ID\", \"count\"),\n",
    "                Follow_Ups=(\"Is_Follow_Up_Required\", \"sum\") if \"Is_Follow_Up_Required\" in insp.columns else (\"Licence_ID\", \"count\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "    )\n",
    "    insp_per_lic[\"Failure_Rate\"] = insp_per_lic[\"Failures\"] / insp_per_lic[\"Inspections\"]\n",
    "else:\n",
    "    insp_per_lic = pd.DataFrame()\n",
    "\n",
    "# Enforcement per licence\n",
    "if \"Licence_ID\" in enf.columns:\n",
    "    enf_per_lic = (\n",
    "        enf.groupby(\"Licence_ID\")\n",
    "           .agg(\n",
    "                Enforcement_Actions=(\"Enforcement_ID\", \"count\") if \"Enforcement_ID\" in enf.columns else (\"Licence_ID\", \"count\")\n",
    "           )\n",
    "           .reset_index()\n",
    "    )\n",
    "else:\n",
    "    enf_per_lic = pd.DataFrame()\n",
    "\n",
    "# Start with licence table and merge in aggregated event metrics\n",
    "licence_level_features = lic.copy()\n",
    "\n",
    "if not comp_per_lic.empty:\n",
    "    licence_level_features = licence_level_features.merge(comp_per_lic, on=\"Licence_ID\", how=\"left\")\n",
    "if not insp_per_lic.empty:\n",
    "    licence_level_features = licence_level_features.merge(insp_per_lic, on=\"Licence_ID\", how=\"left\")\n",
    "if not enf_per_lic.empty:\n",
    "    licence_level_features = licence_level_features.merge(enf_per_lic, on=\"Licence_ID\", how=\"left\")\n",
    "\n",
    "# Replace NaNs created by merges with 0 for event counts (means \"no events recorded\")\n",
    "for col in [\"Complaints\", \"Escalations\", \"Inspections\", \"Failures\", \"Follow_Ups\", \"Enforcement_Actions\"]:\n",
    "    if col in licence_level_features.columns:\n",
    "        licence_level_features[col] = licence_level_features[col].fillna(0)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 11) ML-READY DATASET (simple + transparent)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# This is a basic ML-ready dataset. It is NOT the final model yet.\n",
    "# The aim is to create a table with numeric/categorical features that can be encoded later.\n",
    "\n",
    "ml_ready = licence_level_features.copy()\n",
    "\n",
    "# A simple example target (can be refined):\n",
    "# \"High_Risk\" = 1 if the licence has >=1 inspection failure OR >=2 complaints OR >=1 enforcement action.\n",
    "\n",
    "# This is an interpretable rule-based target suitable for synthetic data, and can be adjusted.\n",
    "high_risk_conditions = []\n",
    "if \"Failures\" in ml_ready.columns:\n",
    "    high_risk_conditions.append(ml_ready[\"Failures\"] >= 1)\n",
    "if \"Complaints\" in ml_ready.columns:\n",
    "    high_risk_conditions.append(ml_ready[\"Complaints\"] >= 2)\n",
    "if \"Enforcement_Actions\" in ml_ready.columns:\n",
    "    high_risk_conditions.append(ml_ready[\"Enforcement_Actions\"] >= 1)\n",
    "\n",
    "if high_risk_conditions:\n",
    "    ml_ready[\"High_Risk\"] = np.logical_or.reduce(high_risk_conditions).astype(int)\n",
    "else:\n",
    "    ml_ready[\"High_Risk\"] = 0  # fallback if event columns are missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13bd6ab-febc-4639-99c9-9f77ba4f5744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 3 complete. Saved files:\n",
      "- county_monthly_summary.csv (dashboard aggregated table)\n",
      "- licence_level_features.csv (dashboard drill-down + ML features)\n",
      "- ml_ready_dataset.csv (ML dataset with a simple High_Risk target)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 12) SAVE OUTPUTS\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Saving these outputs supports reproducibility and makes Phase 4 and Phase 5 easier.\n",
    "county_monthly_summary.to_csv(\"county_monthly_summary.csv\", index=False)\n",
    "licence_level_features.to_csv(\"licence_level_features.csv\", index=False)\n",
    "ml_ready.to_csv(\"ml_ready_dataset.csv\", index=False)\n",
    "\n",
    "print(\"\\nPhase 3 complete. Saved files:\")\n",
    "print(\"- county_monthly_summary.csv (dashboard aggregated table)\")\n",
    "print(\"- licence_level_features.csv (dashboard drill-down + ML features)\")\n",
    "print(\"- ml_ready_dataset.csv (ML dataset with a simple High_Risk target)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c68596-89a5-46ab-8eb4-7d220b817e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preview: county_monthly_summary ---\n",
      "  County      Month  Inspections  Failures  Follow_Ups  Failure_Rate  \\\n",
      "0  CAVAN 2022-01-01           14         2           1      0.142857   \n",
      "1  CAVAN 2022-02-01           14         2           3      0.142857   \n",
      "2  CAVAN 2022-03-01           15         4           3      0.266667   \n",
      "3  CAVAN 2022-04-01           14         3           2      0.214286   \n",
      "4  CAVAN 2022-05-01           25         4           2      0.160000   \n",
      "\n",
      "   Complaints  Escalations  Escalation_Rate  Enforcement_Actions  \n",
      "0        13.0          2.0         0.153846                  6.0  \n",
      "1        13.0          2.0         0.153846                  1.0  \n",
      "2        14.0          3.0         0.214286                  3.0  \n",
      "3        18.0          2.0         0.111111                  5.0  \n",
      "4        11.0          3.0         0.272727                  4.0  \n",
      "\n",
      "--- Preview: licence_level_features ---\n",
      "   Licence_ID Licence_Type Issue_Date Expiry_Date    Status     County  \\\n",
      "0  SPSV_00001         TAXI 2018-07-15  2025-07-13    LAPSED  WESTMEATH   \n",
      "1  SPSV_00002    LIMOUSINE 2025-01-30  2026-01-30  EXPIRING     OFFALY   \n",
      "2  SPSV_00003      HACKNEY 2023-07-21  2027-12-31    ACTIVE      MEATH   \n",
      "3  SPSV_00004         TAXI 2019-08-25  2024-08-23    LAPSED   KILKENNY   \n",
      "4  SPSV_00005         TAXI 2023-07-16  2027-12-31    ACTIVE     GALWAY   \n",
      "\n",
      "  Wheelchair_Accessible  Vehicle_Age             Vehicle_Plate_Year  \\\n",
      "0                    NO            1  1970-01-01 00:00:00.000002024   \n",
      "1                    NO            7  1970-01-01 00:00:00.000002019   \n",
      "2                    NO           11  1970-01-01 00:00:00.000002014   \n",
      "3                    NO            1  1970-01-01 00:00:00.000002024   \n",
      "4                    NO            7  1970-01-01 00:00:00.000002018   \n",
      "\n",
      "         Driver_Experience_Years  ... Days_To_Expiry  Is_Expiring_90_Days  \\\n",
      "0  1970-01-01 00:00:00.000000002  ...           -901                    0   \n",
      "1  1970-01-01 00:00:00.000000011  ...           -700                    0   \n",
      "2  1970-01-01 00:00:00.000000008  ...              0                    1   \n",
      "3  1970-01-01 00:00:00.000000006  ...          -1225                    0   \n",
      "4  1970-01-01 00:00:00.000000013  ...              0                    1   \n",
      "\n",
      "  Complaints  Escalations  Avg_Days_To_Resolution  Inspections  Failures  \\\n",
      "0        4.0          1.0               12.250000          3.0       0.0   \n",
      "1        7.0          1.0               22.000000          4.0       1.0   \n",
      "2        5.0          1.0               12.400000          5.0       1.0   \n",
      "3        5.0          2.0               20.600000          5.0       0.0   \n",
      "4        3.0          0.0                9.333333          3.0       0.0   \n",
      "\n",
      "   Follow_Ups  Failure_Rate  Enforcement_Actions  \n",
      "0         0.0          0.00                  0.0  \n",
      "1         0.0          0.25                  1.0  \n",
      "2         1.0          0.20                  0.0  \n",
      "3         0.0          0.00                  0.0  \n",
      "4         1.0          0.00                  0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "--- Preview: ml_ready_dataset (target distribution) ---\n",
      "High_Risk\n",
      "1    4627\n",
      "0     373\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 13) QUICK PREVIEW \n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n--- Preview: county_monthly_summary ---\")\n",
    "print(county_monthly_summary.head())\n",
    "\n",
    "print(\"\\n--- Preview: licence_level_features ---\")\n",
    "print(licence_level_features.head())\n",
    "\n",
    "print(\"\\n--- Preview: ml_ready_dataset (target distribution) ---\")\n",
    "print(ml_ready[\"High_Risk\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487b4e3-04f6-4ee0-ad54-3e641b122fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
